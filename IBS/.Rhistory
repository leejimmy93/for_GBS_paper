help(plot)
# 2M2
# R code 2.3
# define grid
p_grid <- seq(from = 0, to = 1, length.out = 20)
p_grid
# define prior
prior <- ifelse(p_grid<0.5, 0, 1)
prior
# compute likelihood at each value in grid
likelihood <- dbinom(5, size = 7, prob = p_grid)
likelihood
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
# display the posterior distribution
plot(p_grid, posterior, type = "b",
xlab="probability of water", ylab="posterior probabilty")
mtext("3 points")
help("ifelse")
# 2H3
# define grid
p_grid <- seq(from = 0, to = 1, length.out = 20)
p_grid
# define prior
prior <- ifelse(p_grid<0.1, 0.5, 0)
prior
# compute likelihood at each value in grid
likelihood <- dbinom(1, size = 1, prob = p_grid)
likelihood
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
# display the posterior distribution
plot(p_grid, posterior, type = "b",
xlab="probability of species A", ylab="posterior probabilty")
mtext("2 points")
# R code 3.1
PrPV <- 0.95 # Pr(vam|positive)
PrPM <- 0.01 # Pr(positive|mortal)
PrV <- 0.001 # Pr(vam)
# the Pr of positive
PrP <- PrPV * PrV + PrPM * (1-PrV)
# calculate the Pr of correctly identify a vampire
(PrVP <- PrPV*PrV / PrP)
# R code 3.2, compute posteror for the globe tossing model
# in the begining of this chapter
p_grid <- seq(from=0, to=1, length.out = 1000)
prior <- rep(1, 1000)
likelihood <- dbinom(6, size = 9, prob = p_grid)
posterior <- likelihood * prior
posterior <- posterior/sum(posterior)
str(posterior)
# R code 3.3
samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE) # replace arg means you put back
# the sample you picked
PI(samples, prob = 0.8)
HPDI(samples, prob = 0.8)
help("sample")
# R code 3.4
plot(samples)
# R code 3.5
library(rstan)
library(rethinking)
dens(samples) # plot the density
help("dens")
# R code 3.6
# add up posterior probability where p<0.5 = the posterior probability
# that the proportion of water is less than 0.5
sum(posterior[p_grid < 0.5])
# R code 3.7, add up all of the samples below 0.5, and also divide the resulting count
# by the total number of samples
sum(samples<0.5)/1e4
# R code 3.8, the posterior probability lies between 0.5 and 0.75
sum(samples > 0.5 & samples<0.75)/1e4
samples < 0.5
# R code 3.9, the boundary of the lower 80% posterior probability
quantile(samples, 0.8)
# the boundary of the middle 80% posterior probability lies between 10% and 90% quantile
quantile(samples, c(0.1, 0.9))
help("quantile")
quantile(samples, probs = c(0.8))
help("seq")
seq(0,1,0.25)
#R code 3.11, compute posterior probability and draw 1e4 random samples for
# observing 3 water out of 3 tosses
p_grid <- seq(0,1, length.out = 1000)
prior <- rep(1,1000)
likelihood <- dbinom(3, size = 3, prob = p_grid)
posterior <- likelihood * prior
posterior <- posterior/sum(posterior)
samples<- sample(p_grid, size = 1e4, replace = TRUE, prob = posterior)
# R code 3.12, the 50% percentile confidence intervel
PI(samples, prob = 0.5) # don't quite understand this!
quantile(samples, c(0.25, 0.75))
help(PI)
dbinom(0:2, size = 2, prob = 0.7)
help("dbinom")
dbinom(1:2, size = 2, prob = 0.7)
dbinom(0:2, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(10, size = 2, prob = 0.7)
dummy_w <- rbinom(1e5, size = 2, prob = 0.7)
table(dummy_w)/1e5
help("table")
dummy_w <- rbinom(1e5, size = 9, prob = 0.7)
simplehist(dummy_w, xlab="dummy water count")
w <- rbinom(le4, size = 9, prob = 0.6)
install.packages(c("coda","mvtnorm","devtools"))
install.packages(c("coda", "mvtnorm", "devtools"))
library(devtools)
devtools::install_github("rmcelreath/rethinking")
library(rethinking)
simplehist(w)
w <- rbinom(le4, size = 9, prob = 0.6)
w <- rbinom(le4, size = 9, prob = 0.6)
simplehist(w)
w <- rbinom(le4, size = 9, prob = 0.6)
w <- rbinom(12, size = 9, prob = 0.6)
simplehist(w)
w <- rbinom(1e4, size = 9, prob = 0.6)
simplehist(w)
samples
w <- rbinom(1e4, size = 9, prob = samples)
simplehist(w)
source("http://bioconductor.org/biocLite.R")
biocLite("gdsfmt")
biocLite("SNPRelate")
library("devtools")
install_github("zhengxwen/gdsfmt")
install_github("zhengxwen/SNPRelate")
install_github("zhengxwen/SNPRelate")
library(gdsfmt)
library(SNPRelate)
snpgdsSummary(snpgdsExampleFileName())
genofile <- snpgdsOpen(snpgdsExampleFileName())
(genofile <- snpgdsOpen(snpgdsExampleFileName()))
genofile <- snpgdsOpen(snpgdsExampleFileName())
snpgdsSummary(snpgdsExampleFileName())
# Open a GDS file
genofile <- snpgdsOpen(snpgdsExampleFileName())
(genofile <- snpgdsOpen(snpgdsExampleFileName()))
genofile <- snpgdsOpen(snpgdsExampleFileName())
genofile
get.attr.gdsn(index.gdsn(genofile, "snp.chromosome"))
pca <- snpgdsPCA(genofile, snp.id=snpset.id, num.thread=2)
snpset <- snpgdsLDpruning(genofile, ld.threshold=0.2)
snpset.id <- unlist(snpset)
# Run PCA
pca <- snpgdsPCA(genofile, snp.id=snpset.id, num.thread=2)
ibs <- snpgdsIBS(genofile, num.thread=2)
ibs
ibs <- snpgdsIBS(genofile, num.thread=2)
pop.idx <- order(pop_code)
library(adegenet)
data("nancycats")
mat.fst <- pairwise.fst(nancycats, res.type = "matrix")
fsttab <- Fst(as.loci(nancycats))
install.packages("adegenet")
install.packages("adegenet")
library(adegenet)
data("nancycats")
library("hierfstat")
library("hierfstat")
install.packages("hierfstat")
library("hierfstat")
data("nancycats")
library(pegas)
install.packages("pegas")
library(pegas)
Fst(as.loci(nancycats))
setwd('/Users/ruijuanli/Desktop/revise/Nei/')
# 6224 all 375 accessions, import data and convert to genind format
obj1 <- read.structure('/Users/ruijuanli/Desktop/revise/Nei/375_6224/project_data_for_adegenet.str')
setwd('/Users/ruijuanli/Desktop/revise/Nei/')
obj1 <- read.structure('/Users/ruijuanli/Desktop/revise/Nei/375_6224/project_data_for_adegenet.str')
cluster_1 <- read.structure('/Users/ruijuanli/Desktop/revise/Nei/302_6430/cluster_1_for_adgenet.str')
cluster_2 <- read.structure('/Users/ruijuanli/Desktop/revise/Nei/64_5283/cluster_2_for_adegenet.str')
obj3 <- genind2genpop(obj1)
cluster_1.genepop <- genind2genpop(cluster_1)
cluster_2.genepop <- genind2genpop(cluster_2)
Fst(as.loci(obj3))
install.packages("hierfstat")
install.packages("hierfstat")
library("hierfstat")
install.packages("pegas")
library(pegas)
install.packages("pegas")
Fst(as.loci(obj3))
class(nancycats)
class(obj3)
Fst(as.loci(obj1))
Fst.obj1 <- Fst(as.loci(obj1))
head(Fst.obj1)
Fst.obj1.csv<- write.csv(Fst.obj1)
write.csv(Fst.obj1, file="~/desktop/revise/Fst/")
")
write.csv(Fst.obj1, file="~/desktop/revise/Fst/Fst.obj1.csv")
write.csv(Fst.obj1, file="~/desktop/revise/Fst/Fst.obj1.csv")
write.csv(dist.genpop(obj3, method = 1, diag = FALSE, upper = FALSE), file="~/desktop/revise/Nei/Nei.all.csv)
write.csv(dist.genpop(obj3, method = 1, diag = FALSE, upper = FALSE), file="~/desktop/revise/Nei/Nei.all.csv))
Nei.obj3 <- dist.genpop(obj3, method = 1, diag = FALSE, upper = FALSE)
Nei.cluster_1 <- dist.genpop(cluster_1.genepop, method = 1, diag = FALSE, upper = FALSE)
Nei.cluster_2 <- dist.genpop(cluster_2.genepop, method = 1, diag = FALSE, upper = FALSE)
write.csv(Nei.obj3, file="~/desktop/revise/Nei/Nei.all.csv")
Nei.obj3
write.table(Nei.obj3, file="~/desktop/revise/Nei/Nei.all.csv")
class(Nei.obj3)
dist.genpop(cluster_1.genepop, method = 1, diag = FALSE, upper = FALSE)
dist.genpop(cluster_2.genepop, method = 1, diag = FALSE, upper = FALSE)
write.csv(Fst.obj1, file="~/desktop/revise/Fst/Fst.all.csv")
# R code 3.1
PrPV <- 0.95 # Pr(vam|positive)
PrPM <- 0.01 # Pr(positive|mortal)
PrV <- 0.001 # Pr(vam)
# the Pr of positive
PrP <- PrPV * PrV + PrPM * (1-PrV)
# calculate the Pr of correctly identify a vampire
(PrVP <- PrPV*PrV / PrP)
# R code 3.2, compute posteror for the globe tossing model
# in the begining of this chapter
p_grid <- seq(from=0, to=1, length.out = 1000)
prior <- rep(1, 1000)
likelihood <- dbinom(6, size = 9, prob = p_grid)
posterior <- likelihood * prior
posterior <- posterior/sum(posterior)
str(posterior)
# R code 3.3
samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE) # replace arg means you put back
str(samples)
samples
plot(samples)
Fst.cluster_1 <- Fst(as.loci(cluster_1))
head(Fst.cluster_1)
write.csv(Fst.cluster_1, file = "~/desktop/revise/Fst/Fst.cluster_1.csv")
Fst.cluster_2 <- Fst(as.loci(cluster_2))
head(Fst.cluster_2)
write.csv(Fst.cluster_2, file = "~/desktop/revise/Fst/Fst.cluster_2.csv")
p_grid <- seq(0,1, length.out = 1000)
prior <- rep(1,1000)
likelihood <- dbinom(3, size = 3, prob = p_grid)
posterior <- likelihood * prior
posterior <- posterior/sum(posterior)
samples<- sample(p_grid, size = 1e4, replace = TRUE, prob = posterior)
# R code 3.12, the 50% percentile confidence intervel
PI(samples, prob = 0.5) # don't quite understand this!
quantile(samples, c(0.25, 0.75))
help(PI)
# how to check the underlying code for a defined funtion???
# practice seq()
seq(0,1,length.out = 10)
help(seq)
seq(from = 0, to = 1, length.out = 10)
# R code 3.13, compute the 50% highest posterior density interval
HPDI(samples, prob = 0.5)
# R code 3.14, compute the maximum posterior (MAP)
p_grid[which.max(posterior)]
# using samples to approximate the MAP
chainmode(samples, adj=0.01)
help("chainmode")
# R code 3.16, posterior mean or median
mean(samples)
median(samples)
# R code 3.17, suppose p=0.5 is our decision, the expected loss will be
sum(posterior*abs(0.5 - p_grid))
# R code 3.18, using sapply to repeat calculation, pick every number from p_grid to see
# which is the best decision.
loss <- sapply(p_grid, function(d) sum(posterior*abs(d-p_grid))) # pick every p_grid and apply
# some fxn to it, function(d): define the fxn, but this fxn is only used here; the last arg
# applys the function on p_grid, in here it may works like take an item from p_grid, and subtract
# every item in p_grid to see how far this item (d) is away from every item in p_grid.
help(sapply) # learn more about sapply
# R code 3.19, finding the parameter value that minimize the loss
p_grid[which.min(loss)]
# 03/03/2016
# R code 3.20
dbinom(0:2, size = 2, prob = 0.7)
help("dbinom")
# R code 3.21, a single dummy data observation of w can be sampled with, among two tosses,
# how many times you can see "w", with the prob of 0.7
rbinom(1, size = 2, prob = 0.7)
#R code 3.22, a set of 10 simulations can be made by
rbinom(10, size = 2, prob = 0.7)
# R code 3.23, generate 100,000 dummy observations, to verify that each value appears
# in proportion to its likelihood
dummy_w <- rbinom(1e5, size = 2, prob = 0.7)
table(dummy_w)/1e5
help("table")
# R code 3.24, simulate the same sample as before, 9 tosses
dummy_w <- rbinom(1e5, size = 9, prob = 0.7)
library(rethinking)
simplehist(dummy_w, xlab="dummy water count")
# R code 3.25, to simulate predicted obervations for a single value of p=0.6, and
# to generate random binomial samples
w <- rbinom(1e4, size = 9, prob = 0.6)
str(w)
samples
min(samples)
max(samples)
plot(samples)
source("http://www.bioconductor.org/biocLite.R")
biocLite("multtest")
source("http://www.bioconductor.org/biocLite.R")
biocLite("multtest")
source("http://www.bioconductor.org/biocLite.R")
biocLite("multtest")
install.packages("gplots")
install.packages("LDheatmap")
install.packages("genetics")
install.packages("scatterplot3d")
library(multtest)
library(gplots)
library(LDheatmap)
library(genetics)
library(compiler) #this library is already installed in R
library("scatterplot3d")
source("http://zzlab.net/GAPIT/gapit_functions.txt")
source("http://zzlab.net/GAPIT/emma.txt")
setwd("~/Desktop/revise/IBS/")
myY=read.table("fake_genotype.txt", head=TRUE)
myG=read.table("375_6224_clean_ID.hmp.txt", head=F)
myGAPIT <- GAPIT(Y=myY, G=myG, Model.selection=TRUE, PCA.total=0, kinship.algorithm=c("EMMA"))
install.packages(c("coda","mvtnorm","devtools"))
library(devtools)
devtools::install_github("rmcelreath/rethinking")
library(rethinking)
install.packages(c("coda", "mvtnorm", "devtools"))
setwd('/Users/ruijuanli/Desktop/revise/Fst/')
all <- read.delim("Fst.all.Fst")
cluster1 <- read.delim("Fst.clucluster1.Fst")
cluster2 <- read.delim("Fst.cluster2.Fst")
setwd('/Users/ruijuanli/Desktop/revise/Fst/')
all <- read.delim("Fst.all.Fst")
cluster1 <- read.delim("Fst.cluster1.Fst")
cluster2 <- read.delim("Fst.cluster2.Fst")
setwd('/Users/ruijuanli/Desktop/revise/Fst/')
all <- read.delim("Fst.all.Fst")
all <- read.delim("Fst.all.csv")
cluster1 <- read.delim("Fst.cluster1.csv")
cluster1 <- read.delim("Fst.cluster_1.csv")
cluster2 <- read.delim("Fst.cluster_2.csv")
head(all)
all <- read.delim("Fst.all.csv", header = F)
cluster1 <- read.delim("Fst.cluster_1.csv", header = F)
cluster2 <- read.delim("Fst.cluster_2.csv", header = F)
head(all)
all <- read.csv("Fst.all.csv")
cluster1 <- read.csv("Fst.cluster_1.csv")
cluster2 <- read.csv("Fst.cluster_2.csv")
head(all)
all.Fst <- all$Fst
cluster1.Fst <- cluster1$Fst
all.Fst <- all$Fst
cluster1.Fst <- cluster1$Fst
cluster2.Fst <- cluster2$Fst
dens(all.Fst)
dens(cluster1.Fst, add = TRUE)
dens(cluster2.Fst, add = TRUE)
dens(all.Fst, ylim=c(0,15))
dens(cluster1.Fst, add = TRUE)
dens(cluster2.Fst, add = TRUE)
dens(cluster1.Fst)
dens(all.Fst, ylim=c(0,20))
dens(cluster1.Fst, add = TRUE)
dens(cluster2.Fst, add = TRUE)
dens(all.Fst, ylim=c(0,20), col="black")
dens(cluster1.Fst, add = TRUE, col="green")
dens(cluster2.Fst, add = TRUE, col="red")
dens(all.Fst, ylim=c(0,20), col="black", xlab="Fst")
dens(cluster1.Fst, add = TRUE, col="green")
dens(cluster2.Fst, add = TRUE, col="red")
setwd('/Users/ruijuanli/Desktop/revise/MAF_call_rate_heterozygosity/')
# load lib for figure
install.packages(c("coda","mvtnorm","devtools"))
library(devtools)
devtools::install_github("rmcelreath/rethinking")
library(rethinking)
install.packages(c("coda", "mvtnorm", "devtools"))
list.files()
firstSNP <- read.delim('/Users/ruijuanli/Desktop/revise/MAF_call_rate_heterozygosity/raw_SNP_hapmap_data/61822.txt')
secondSNP <- read.delim('/Users/ruijuanli/Desktop/revise/MAF_call_rate_heterozygosity/raw_SNP_hapmap_data/18571.txt')
thirdSNP <- read.delim('/Users/ruijuanli/Desktop/revise/MAF_call_rate_heterozygosity/raw_SNP_hapmap_data/6224.txt')
head(firstSNP)
###################
# call rate, MAF, & heterozygosity rate for each accession at each step of SNP filtering
###################
# MAF
firstSNP.MAF <- firstSNP$Minor.Allele.Frequency
secondSNP.MAF<- secondSNP$Minor.Allele.Frequency
thirdSNP.MAF<- thirdSNP$Minor.Allele.Frequency
density()
help("density")
summary(firstSNP.MAF)
summary(secondSNP.MAF)
summary(thirdSNP.MAF)
# missing rate
firstSNP.missingrate <- firstSNP$Proportion.Missing
secondSNP.missingrate <- secondSNP$Proportion.Missing
thirdSNP.missingrate <- thirdSNP$Proportion.Missing
# heterozygosity
firstSNP.heterozygosity <- firstSNP$Proportion.Heterozygous
secondSNP.heterozygosity <- secondSNP$Proportion.Heterozygous
thirdSNP.heterozygosity <- thirdSNP$Proportion.Heterozygous
# making plot
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density")
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", weight = 2)
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", weight=c(2))
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", weight=2)
?density
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", weights=2)
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", weights=5)
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", weights=9)
?density
?"plot"
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", pch=9)
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", pch=1)
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", lwd=1)
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", lwd=2)
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", lwd=2)
dens(firstSNP.MAF, add = TRUE, col="black", lwd=2)
dens(thirdSNP.MAF, add = TRUE, col="red", lwd=2)
dens(firstSNP.missingrate, ylim=c(0,20), col="black", xlab="missing rate", ylab="density",lwd=2)
dens(secondSNP.missingrate, xlim=c(0, 1), add = TRUE, col="blue", lwd=2)
dens(thirdSNP.missingrate, add = TRUE, col="red", lwd=2)
dens(firstSNP.heterozygosity, col="black", xlab="heterozygosity", ylab="density", lwd=2)
dens(secondSNP.heterozygosity, add=TRUE, col="blue", lwd=2)
dens(thirdSNP.heterozygosity, add = TRUE, col="red", lwd=2)
SNP_1st_cluster <- read.delim('/Users/ruijuanli/Desktop/revise/MAF_call_rate_heterozygosity/6224_302.txt')
SNP_2nd_cluster <- read.delim('/Users/ruijuanli/Desktop/revise/MAF_call_rate_heterozygosity/64_6224.txt')
two_hundred_and_three_accessions <- read.delim('/Users/ruijuanli/Desktop/revise/MAF_call_rate_heterozygosity/203_6430.txt')
seventy_seven_accessions <- read.delim('/Users/ruijuanli/Desktop/revise/MAF_call_rate_heterozygosity/77_6430.txt')
ten_accessions <- read.delim('/Users/ruijuanli/Desktop/revise/MAF_call_rate_heterozygosity/10_5283.txt')
forty_accessions <- read.delim('/Users/ruijuanli/Desktop/revise/MAF_call_rate_heterozygosity/40_5283.txt')
six_accessions <- read.delim('/Users/ruijuanli/Desktop/revise/MAF_call_rate_heterozygosity/6_5283.txt')
###################
# call rate, MAF, & heterozygosity rate
###################
# MAF
SNP_1st_cluster.MAF <- SNP_1st_cluster$Minor.Allele.Frequency
SNP_2nd_cluster.MAF <- SNP_2nd_cluster$Minor.Allele.Frequency
two_hundred_and_three_accessions.MAF <- two_hundred_and_three_accessions$Minor.Allele.Frequency
seventy_seven_accessions.MAF<- seventy_seven_accessions$Minor.Allele.Frequency
ten_accessions.MAF<- ten_accessions$Minor.Allele.Frequency
forty_accessions.MAF <- forty_accessions$Minor.Allele.Frequency
six_accessions.MAF <- six_accessions$Minor.Allele.Frequency
summary(SNP_1st_cluster.MAF)
summary(SNP_2nd_cluster.MAF)
summary(two_hundred_and_three_accessions.MAF)
summary(seventy_seven_accessions.MAF)
summary(ten_accessions.MAF)
summary(forty_accessions.MAF)
summary(six_accessions.MAF)
# missing rate
SNP_1st_cluster.missingrate <- SNP_1st_cluster$Proportion.Missing
SNP_2nd_cluster.missingrate <- SNP_2nd_cluster$Proportion.Missing
two_hundred_and_three_accessions.missingrate <- two_hundred_and_three_accessions$Proportion.Missing
seventy_seven_accessions.missingrate<- seventy_seven_accessions$Proportion.Missing
ten_accessions.missingrate<- ten_accessions$Proportion.Missing
forty_accessions.missingrate <- forty_accessions$Proportion.Missing
six_accessions.missingrate <- six_accessions$Proportion.Missing
# heterozygosity
SNP_1st_cluster.heterozygosity <- SNP_1st_cluster$Proportion.Heterozygous
SNP_2nd_cluster.heterozygosity <- SNP_2nd_cluster$Proportion.Heterozygous
two_hundred_and_three_accessions.heterozygosity <- two_hundred_and_three_accessions$Proportion.Heterozygous
seventy_seven_accessions.heterozygosity<- seventy_seven_accessions$Proportion.Heterozygous
ten_accessions.heterozygosity<- ten_accessions$Proportion.Heterozygous
forty_accessions.heterozygosity <- forty_accessions$Proportion.Heterozygous
six_accessions.heterozygosity <- six_accessions$Proportion.Heterozygous
# making plot
dens(thirdSNP.MAF, col="black", xlab="Minor allele frequency", ylab="density", lwd=2)
dens(SNP_1st_cluster.MAF, add = TRUE, col="green", lwd=2)
dens(SNP_2nd_cluster.MAF, add = TRUE, col="red", lwd=2)
dens(secondSNP.MAF, col="blue", xlab="Minor allele frequency", ylab="density", lwd=2)
dens(firstSNP.MAF, add = TRUE, col="black", lwd=2)
dens(thirdSNP.MAF, add = TRUE, col="red", lwd=2)
dens(firstSNP.missingrate, ylim=c(0,20), col="black", xlab="missing rate", ylab="density",lwd=2)
dens(secondSNP.missingrate, xlim=c(0, 1), add = TRUE, col="blue", lwd=2)
dens(thirdSNP.missingrate, add = TRUE, col="red", lwd=2)
dens(firstSNP.heterozygosity, col="black", xlab="heterozygosity", ylab="density", lwd=2)
dens(secondSNP.heterozygosity, add=TRUE, col="blue", lwd=2)
dens(thirdSNP.heterozygosity, add = TRUE, col="red", lwd=2)
install.packages(c("coda","mvtnorm","devtools"))
library(devtools)
devtools::install_github("rmcelreath/rethinking")
library(rethinking)
setwd('/Users/ruijuanli/Desktop/revise/Fst/')
all <- read.csv("Fst.all.csv")
cluster1 <- read.csv("Fst.cluster_1.csv")
cluster2 <- read.csv("Fst.cluster_2.csv")
all.Fst <- all$Fst
cluster1.Fst <- cluster1$Fst
cluster2.Fst <- cluster2$Fst
install.packages(c("coda", "mvtnorm", "devtools"))
dens(all.Fst, ylim=c(0,20), col="black", xlab="Fst", lwd=2)
dens(cluster1.Fst, add = TRUE, col="green", lwd=2)
dens(cluster2.Fst, add = TRUE, col="red", lwd=2)
